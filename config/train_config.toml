[model]
[model.shared]
latent_size = 424
transformation_dimension_size = 512
[model.encoder]
grid_size = 900
attention_sizes = [512, 1024, 1024]
hidden_sizes = [1024, 4]
learning_rate = 0.001
tau = 0.85
[model.transformer]
learning_rate = 0.001
alpha = 0.9
[model.encoder.downstream_attributes]
grid_size = {output_size = 2, output_channels=30}
num_colors = {output_size = 1, output_channels=10}
[model.encoder.contrastive_attributes]
roll = {task_type = "task_sensitive", activation = "sigmoid"}
scale_grid = {task_type = "task_sensitive", activation = "sigmoid"}
isolate_color = {task_type = "task_sensitive", activation = "sigmoid"}
rotate = {task_type = "task_insensitive"}
reflect = {task_type = "task_insensitive"}
color_map = {task_type = "task_insensitive"}

[training]
[training.shared]
dataset_path = "training"
[training.encoder]
batch_size = 1317
epochs = 10000
[training.transformer]
batch_size = 1
epochs = 1