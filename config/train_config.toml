[model]
[model.shared]
latent_size = 424
transformation_dimension_size = 512
[model.encoder]
grid_size = 900
attention_sizes = [512, 1024, 1024]
hidden_sizes = [256, 10]
learning_rate = 0.001
tau = 0.85
[model.transformer]
learning_rate = 0.001
alpha = 0.9
[model.encoder.downstream_attributes]
grid_size = {hidden_sizes=[64, 10], output_sizes=[2, 30]}
num_colors = {hidden_sizes=[64, 10], output_sizes=[1, 10]}
[model.encoder.contrastive_attributes]
roll = {hidden_sizes=[64, 10], task_type = "task_sensitive"}
scale_grid = {hidden_sizes=[64, 10], task_type = "task_sensitive"}
isolate_color = {hidden_sizes=[64, 10], task_type = "task_sensitive"}
rotate = {task_type = "task_insensitive"}
reflect = {task_type = "task_insensitive"}
color_map = {task_type = "task_insensitive"}

[training]
[training.shared]
dataset_path = "training"
[training.encoder]
batch_size = 150
epochs = 10000
[training.transformer]
batch_size = 1
epochs = 1